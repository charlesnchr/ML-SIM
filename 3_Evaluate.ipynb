{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import skimage\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndimage\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from skimage import io,exposure,img_as_ubyte\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from models import GetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel(opt):\n",
    "    print('Loading model')\n",
    "    print(opt)\n",
    "\n",
    "    net = GetModel(opt)\n",
    "    print('loading checkpoint',opt.weights)\n",
    "    checkpoint = torch.load(opt.weights,map_location=opt.device)\n",
    "\n",
    "    if type(checkpoint) is dict:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def SIM_reconstruct(model, opt):\n",
    "    \n",
    "    def prepimg(stack,self):\n",
    "\n",
    "        inputimg = stack[:9]\n",
    "\n",
    "        if self.nch_in == 6:\n",
    "            inputimg = inputimg[[0,1,3,4,6,7]]\n",
    "        elif self.nch_in == 3:\n",
    "            inputimg = inputimg[[0,4,8]]\n",
    "\n",
    "        if inputimg.shape[1] > 512 or inputimg.shape[2] > 512:\n",
    "            print('Over 512x512! Cropping')\n",
    "            inputimg = inputimg[:,:512,:512]\n",
    "\n",
    "        inputimg = inputimg.astype('float') / np.max(inputimg) # used to be /255\n",
    "        widefield = np.mean(inputimg,0) \n",
    "\n",
    "        if self.norm == 'adapthist':\n",
    "            for i in range(len(inputimg)):\n",
    "                inputimg[i] = exposure.equalize_adapthist(inputimg[i],clip_limit=0.001)\n",
    "            widefield = exposure.equalize_adapthist(widefield,clip_limit=0.001)\n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "        else:\n",
    "            # normalise \n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "            widefield = (widefield - torch.min(widefield)) / (torch.max(widefield) - torch.min(widefield))\n",
    "\n",
    "            if self.norm == 'minmax':\n",
    "                for i in range(len(inputimg)):\n",
    "                    inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n",
    "\n",
    "        return inputimg,widefield\n",
    "\n",
    "    os.makedirs('%s' % opt.out,exist_ok=True)\n",
    "    files = glob.glob('%s/*.tif' % opt.root)\n",
    "    \n",
    "    for iidx,imgfile in enumerate(files):\n",
    "        \n",
    "        print('[%d/%d] Reconstructing %s' % (iidx+1,len(files),imgfile))\n",
    "        stack = io.imread(imgfile)\n",
    "        \n",
    "        inputimg, wf = prepimg(stack,opt)\n",
    "        wf = (255*wf.numpy()).astype('uint8')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sr = model(inputimg.unsqueeze(0).to(opt.device))\n",
    "            sr = sr.cpu()\n",
    "            sr = torch.clamp(sr,min=0,max=1) \n",
    "\n",
    "        sr = sr.squeeze().numpy()\n",
    "        sr = (255*sr).astype('uint8')\n",
    "        if opt.norm == 'adapthist':\n",
    "            sr = exposure.equalize_adapthist(sr,clip_limit=0.01)\n",
    "\n",
    "        skimage.io.imsave('%s/test_wf_%d.jpg' % (opt.out,iidx), wf)\n",
    "        skimage.io.imsave('%s/test_sr_%d.jpg' % (opt.out,iidx), sr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run example model trained with `2_Train.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'Test_data'\n",
    "opt.out = 'test_output'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.norm = 'minmax'\n",
    "opt.dataset = 'fouriersim'\n",
    "\n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = 'model_output/final.pth'\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.narch = 0\n",
    "opt.n_resblocks = 3\n",
    "opt.n_resgroups = 5\n",
    "opt.reduction = 16\n",
    "opt.n_feats = 48\n",
    "\n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = False\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pre-trained model provided as a download file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the model file at:\n",
    "    - https://ml-sim.s3.eu-west-2.amazonaws.com/pdist/models/DIV2K_randomised_3x3_20200317.pth\n",
    "- Put the downloaded model in the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'Test_data'\n",
    "opt.out = 'test_output'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.norm = 'minmax'\n",
    "opt.dataset = 'fouriersim'\n",
    "\n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = 'DIV2K_randomised_3x3_20200317.pth'\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.n_resgroups = 3\n",
    "opt.n_resblocks = 10\n",
    "opt.n_feats = 96\n",
    "opt.reduction = 16\n",
    "opt.narch = 0\n",
    "\n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = False\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Namespace(cpu=True, dataset='fouriersim', device=device(type='cpu'), imageSize=512, model='rcan', n_feats=96, n_resblocks=10, n_resgroups=3, narch=0, nch_in=9, nch_out=1, norm='minmax', out='test_output', reduction=16, root='Test_data', scale=1, task='simin_gtout', test=False, weights='./DIV2K_randomised_3x3_20200317.pth')\n",
      "loading checkpoint ./DIV2K_randomised_3x3_20200317.pth\n",
      "[1/6] Reconstructing Test_data/barbara.tif\n",
      "[2/6] Reconstructing Test_data/SLM-SIM beads.tif\n",
      "[3/6] Reconstructing Test_data/SLM-SIM syrlyso640-5.tif\n",
      "[4/6] Reconstructing Test_data/AtheiSIM 14-52_488.tif\n",
      "[5/6] Reconstructing Test_data/AtheiSIM 13-43_488.tif\n",
      "[6/6] Reconstructing Test_data/penguin.tif\n"
     ]
    }
   ],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
